# Project Glamira ETL Pipeline

## ğŸ“– Giá»›i thiá»‡u dá»± Ã¡n
Project Glamira lÃ  má»™t Data Pipeline (ETL) hoÃ n chá»‰nh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a viá»‡c trÃ­ch xuáº¥t (Extract), biáº¿n Ä‘á»•i (Transform) vÃ  táº£i (Load) dá»¯ liá»‡u hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  thÃ´ng tin sáº£n pháº©m tá»« há»‡ thá»‘ng. 

Äáº·c biá»‡t, module Crawler Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i cÆ¡ cháº¿ Anti-Bot máº¡nh máº½, kháº£ nÄƒng chá»‹u lá»—i (Fault-tolerance) vÃ  tá»± Ä‘á»™ng ghi nhá»› tiáº¿n trÃ¬nh (Checkpoint) Ä‘á»ƒ hoáº¡t Ä‘á»™ng bá»n bá»‰ trÃªn mÃ´i trÆ°á»ng Cloud (Google Cloud Platform - GCP).

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c (Project Structure)

```text
UNIGAP-ProjectGlamira/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ get_mongo_connection.py      # Thiáº¿t láº­p káº¿t ná»‘i Ä‘áº¿n MongoDB
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Dá»¯ liá»‡u gá»‘c (chÆ°a xá»­ lÃ½)
â”‚   â””â”€â”€ processed/                   # Dá»¯ liá»‡u xuáº¥t ra vÃ  file Checkpoint
â”‚       â”œâ”€â”€ error_404_productid.txt  # Log ID sáº£n pháº©m bá»‹ lá»—i 404
â”‚       â”œâ”€â”€ success_productid.txt    # Log ID sáº£n pháº©m Ä‘Ã£ crawl thÃ nh cÃ´ng (Checkpoint)
â”‚       â””â”€â”€ product_names.csv        # File CSV backup/log káº¿t quáº£ crawl
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ product_crawler.py       # Script crawl tÃªn sáº£n pháº©m 
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ transform/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ip_processing.py         # Script xá»­ lÃ½ chuáº©n hÃ³a IP ngÆ°á»i dÃ¹ng
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ checkpoint_manager.py        # Quáº£n lÃ½ Ä‘á»c/ghi Checkpoint (TrÃ¡nh crawl láº¡i)
â”‚   â””â”€â”€ get_data_from_env.py         # Äá»c cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n tá»« file .env
â”œâ”€â”€ tests/                           
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .env                             # File chá»©a biáº¿n mÃ´i trÆ°á»ng
â”œâ”€â”€ .gitignore                       # File bá» qua cÃ¡c file khÃ´ng cáº§n push lÃªn Git
â”œâ”€â”€ poetry.lock                      # KhÃ³a phiÃªn báº£n cÃ¡c thÆ° viá»‡n dependencies
â”œâ”€â”€ pyproject.toml                   # Cáº¥u hÃ¬nh dá»± Ã¡n & danh sÃ¡ch thÆ° viá»‡n (Poetry)
â””â”€â”€ README.md                        # TÃ i liá»‡u dá»± Ã¡n
```

---

## TÃ­nh nÄƒng ná»•i báº­t
1. CÆ¡ cháº¿ Anti-Bot & VÆ°á»£t TÆ°á»ng Lá»­a (Bypass 403/429):

* Giáº£ láº­p TLS Fingerprint thÃ´ng qua thÆ° viá»‡n curl_cffi (Ä‘Ã³ng giáº£ Chrome, Edge, Safari).

* TÃ­ch há»£p máº¡ng lÆ°á»›i Proxy (tá»« webshare.io) Ä‘á»ƒ xoay vÃ²ng IP, trÃ¡nh bá»‹ block IP khi cháº¡y trÃªn mÃ¡y áº£o GCP.

2. Quáº£n lÃ½ Tiáº¿n trÃ¬nh ThÃ´ng minh (Checkpointing):

* Sá»­ dá»¥ng checkpoint_manager.py Ä‘á»ƒ lÆ°u trá»¯ tráº¡ng thÃ¡i cÃ¡c ID Ä‘Ã£ xá»­ lÃ½ vÃ o data/processed/. Náº¿u script bá»‹ ngáº¯t giá»¯a chá»«ng (do cÃºp Ä‘iá»‡n, rá»›t máº¡ng), láº§n cháº¡y sau sáº½ tá»± Ä‘á»™ng bá» qua cÃ¡c ID Ä‘Ã£ lÃ m xong, tiáº¿t kiá»‡m tá»‘i Ä‘a thá»i gian.

3. Xá»­ lÃ½ & Chuáº©n hÃ³a Vá»‹ trÃ­ IP (IP Processing):

* TÃ­ch há»£p thÆ° viá»‡n IP2Location vÃ  quÃ©t file .BIN cá»¥c bá»™ Ä‘á»ƒ giáº£i mÃ£ nhanh vá»‹ trÃ­ (Quá»‘c gia, VÃ¹ng, ThÃ nh phá»‘) mÃ  khÃ´ng cáº§n gá»i API bÃªn ngoÃ i.

* Data Quality Control: Tá»± Ä‘á»™ng lá»c bá» cÃ¡c IP khÃ´ng há»£p lá»‡, thiáº¿u thÃ´ng tin vá»‹ trÃ­ (-, n/a, N/A).

4. Tá»‘i Æ°u hÃ³a Database (MongoDB):

* PhÃ¢n lÃ´ dá»¯ liá»‡u tá»± Ä‘á»™ng (Cursor Batching) giá»›i háº¡n batch_size(100) giÃºp xá»­ lÃ½ mÆ°á»£t mÃ  hÃ ng chá»¥c ngÃ n báº£n ghi mÃ  khÃ´ng bá»‹ lá»—i.

* Há»— trá»£ Compound Indexes giÃºp tÄƒng tá»‘c Ä‘á»™ truy váº¥n data tá»« raw_data.

---

## HÆ°á»›ng dáº«n cÃ i Ä‘áº·t (MÃ´i trÆ°á»ng Ubuntu/GCP)
1. YÃªu cáº§u há»‡ thá»‘ng (Prerequisites)
* Há»‡ Ä‘iá»u hÃ nh: Linux (Ubuntu/Debian) hoáº·c MacOS.

* Python: >= 3.10

* Package Manager: Poetry

2. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng áº£o vÃ  thÆ° viá»‡n
Dá»± Ã¡n sá»­ dá»¥ng Poetry Ä‘á»ƒ quáº£n lÃ½ thÆ° viá»‡n cháº·t cháº½. CÃ i Ä‘áº·t cÃ¡c dependencies báº±ng lá»‡nh sau:

```
# Ã‰p Poetry táº¡o thÆ° má»¥c .venv ngay bÃªn trong thÆ° má»¥c dá»± Ã¡n
poetry config virtualenvs.in-project true

# CÃ i Ä‘áº·t toÃ n bá»™ thÆ° viá»‡n tá»« file pyproject.toml
poetry install
```
3. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng (.env)
* Táº¡o má»™t file .env á»Ÿ thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n vÃ  khai bÃ¡o cÃ¡c thÃ´ng sá»‘ sau:

```
# Cáº¥u hÃ¬nh MongoDB
MONGO_URI=mongodb+srv://<username>:<password>@cluster.mongodb.net/
DB_NAME='your_db'

# ÄÆ°á»ng dáº«n lÆ°u file log
PRODUCT_NAME_PATH='UNIGAP-ProjectGlamira/data/processed/product_names.csv'

# IP data path
IP_DATA_PATH = "UNIGAP-ProjectGlamira/data/raw/ip_data/IP-COUNTRY-REGION-CITY.BIN"

#Checkpoint file path
SUCCESS_FILE_PATH = 'UNIGAP-ProjectGlamira/data/processed/success_productid.txt'
ERROR_404_FILE_PATH = 'UNIGAP-ProjectGlamira/data/processed/error_404_productid.txt'
```

4. Cáº¥u hÃ¬nh Proxy (Báº¯t buá»™c khi cháº¡y trÃªn Cloud)
* Má»Ÿ file etl/extract/product_crawler.py, tÃ¬m Ä‘áº¿n list proxy_list vÃ  cáº­p nháº­t danh sÃ¡ch proxy cá»§a báº¡n (VD: tá»« Webshare) theo Ä‘á»‹nh dáº¡ng:
http://username:password@ip_address:port
 
---

## HÆ°á»›ng dáº«n cháº¡y Script
1. Ká»‹ch báº£n 1: Cháº¡y Crawler thu tháº­p tÃªn sáº£n pháº©m
* Äá»ƒ cháº¡y ká»‹ch báº£n cÃ o dá»¯ liá»‡u, hÃ£y Ä‘á»©ng á»Ÿ thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n vÃ  sá»­ dá»¥ng lá»‡nh poetry run:

```
poetry run python -m etl.extract.product_crawler
```

* Luá»“ng hoáº¡t Ä‘á»™ng cá»§a Script:

  * Káº¿t ná»‘i MongoDB, láº¥y ra tá»•ng sá»‘ ID cáº§n crawl tá»« báº£ng raw_data.

  * Äá»‘i chiáº¿u vá»›i file success_productid.txt Ä‘á»ƒ loáº¡i trá»« cÃ¡c ID Ä‘Ã£ hoÃ n thÃ nh.

  * Chia lÃ´ nhá» (Batch) vÃ  gá»i Ä‘a luá»“ng (Multi-threading) káº¿t há»£p vá»›i xoay vÃ²ng Proxy.

  * Xá»­ lÃ½ logic bÃ³c tÃ¡ch HTML Ä‘á»ƒ láº¥y tÃªn sáº£n pháº©m.

  * Ghi realtime tráº¡ng thÃ¡i vÃ o file text (Checkpoint), ghi log vÃ o file CSV vÃ  lÆ°u data sáº¡ch vÃ o Collection product_names trong MongoDB.

2. Ká»‹ch báº£n 2: Cháº¡y Transform xá»­ lÃ½ Ä‘á»‹nh vá»‹ IP
* Äá»ƒ cháº¡y ká»‹ch báº£n xá»­ lÃ½ Ä‘á»‹nh vá»‹ IP, hÃ£y Ä‘á»©ng á»Ÿ thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n vÃ  sá»­ dá»¥ng lá»‡nh poetry run:

```
poetry run python -m etl.transform.ip_processing
```

* Luá»“ng hoáº¡t Ä‘á»™ng cá»§a Script:

  * QuÃ©t collection raw_data vÃ  sá»­ dá»¥ng Pipeline Aggregation Ä‘á»ƒ gom nhÃ³m cÃ¡c IP duy nháº¥t (Unique IPs).

  * Load database cá»¥c bá»™ .BIN cá»§a IP2Location.

  * Tiáº¿n hÃ nh Ä‘á»‘i chiáº¿u, chuáº©n hÃ³a Data Quality (loáº¡i bá» dá»¯ liá»‡u rÃ¡c, thiáº¿u thÃ´ng tin).

  * LÆ°u Ä‘á»“ng loáº¡t (Bulk Insert) dá»¯ liá»‡u sáº¡ch vÃ o collection ip_locations.

---

## Quáº£n lÃ½ dá»¯ liá»‡u log (Reset tiáº¿n trÃ¬nh)
Náº¿u báº¡n muá»‘n cháº¡y láº¡i dá»¯ liá»‡u tá»« con sá»‘ 0, hÃ£y xÃ³a cÃ¡c file checkpoint trong thÆ° má»¥c processed:

```
rm data/processed/*
```

---

## Háº¡n cháº¿ hiá»‡n táº¡i (Limitations)

DÃ¹ Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a, dá»± Ã¡n hiá»‡n táº¡i váº«n cÃ²n má»™t sá»‘ giá»›i háº¡n nháº¥t Ä‘á»‹nh:
1. **Phá»¥ thuá»™c vÃ o Proxy miá»…n phÃ­:** Do sá»­ dá»¥ng gÃ³i Proxy Datacenter miá»…n phÃ­ (Webshare), tiáº¿n trÃ¬nh Crawler bá»‹ giá»›i háº¡n bÄƒng thÃ´ng (1GB/thÃ¡ng). Náº¿u crawl dá»¯ liá»‡u lá»›n (>10.000 trang), há»‡ thá»‘ng sáº½ tráº£ vá» lá»—i `402 Payment Required`.
2. **Äá»™ nháº¡y cáº£m vá»›i cáº¥u trÃºc HTML:** Logic bÃ³c tÃ¡ch tÃªn sáº£n pháº©m phá»¥ thuá»™c vÃ o cáº¥u trÃºc tháº» HTML hiá»‡n táº¡i cá»§a website (VD: `h1.page-title span`, tháº» `meta og:title`). Náº¿u phÃ­a website thay Ä‘á»•i giao diá»‡n, hÃ m BeautifulSoup cÃ³ thá»ƒ sáº½ khÃ´ng báº¯t Ä‘Æ°á»£c dá»¯ liá»‡u.
3. **Dá»¯ liá»‡u IP tÄ©nh:** Module IP Processing Ä‘ang sá»­ dá»¥ng file Database cá»¥c bá»™ (`.BIN`). Náº¿u khÃ´ng táº£i báº£n cáº­p nháº­t má»›i thÆ°á»ng xuyÃªn, má»™t sá»‘ dáº£i IP má»›i cáº¥p phÃ¡t cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c nháº­n diá»‡n chÃ­nh xÃ¡c.
4. **Thiáº¿u tÃ­nh nÄƒng Tá»± Ä‘á»™ng hÃ³a & Láº­p lá»‹ch:** Hiá»‡n táº¡i, Pipeline váº«n Ä‘ang Ä‘Æ°á»£c kÃ­ch hoáº¡t thá»§ cÃ´ng (Manual trigger) thÃ´ng qua cÃ¡c lá»‡nh terminal trÃªn mÃ¡y áº£o.

---

## Äá»‹nh hÆ°á»›ng cáº£i tiáº¿n (Future Roadmap)

Äá»ƒ biáº¿n dá»± Ã¡n thÃ nh má»™t há»‡ thá»‘ng Data Platform cáº¥p Ä‘á»™ doanh nghiá»‡p (Enterprise-level), dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c bÆ°á»›c cáº£i tiáº¿n tiáº¿p theo:

1. **TÃ­ch há»£p Cloud Data Lake (GCS):** XÃ¢y dá»±ng module `export_to_gcs.py` Ä‘á»ƒ tá»± Ä‘á»™ng xuáº¥t dá»¯ liá»‡u sáº¡ch tá»« MongoDB sang Ä‘á»‹nh dáº¡ng tá»‘i Æ°u (Parquet/JSONL) vÃ  Ä‘áº©y lÃªn **Google Cloud Storage (GCS)**.
2. **ÄÆ°a dá»¯ liá»‡u lÃªn Data Warehouse:** Thiáº¿t láº­p luá»“ng Ä‘áº©y dá»¯ liá»‡u tá»« GCS vÃ o **Google BigQuery** Ä‘á»ƒ phá»¥c vá»¥ cho cÃ¡c team Data Analytics/BI truy váº¥n vÃ  lÃ m bÃ¡o cÃ¡o.
3. **NÃ¢ng cáº¥p háº¡ táº§ng Proxy:** Chuyá»ƒn Ä‘á»•i sang cÃ¡c dá»‹ch vá»¥ Rotating Residential Proxy tráº£ phÃ­ (nhÆ° BrightData, SmartProxy) hoáº·c cÃ¡c API Scraping chuyÃªn dá»¥ng Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ crawl (lÃªn 50-100 luá»“ng) vÃ  trÃ¡nh hoÃ n toÃ n lá»—i 402/403.
4. **LÃªn lá»‹ch tá»± Ä‘á»™ng (Orchestration):** ÄÆ°a toÃ n bá»™ cÃ¡c script nÃ y vÃ o cÃ¡c tool xá»­ lÃ½ cháº¡y tá»± Ä‘á»™ng (Apache Airflow, ...) (thay vÃ¬ cháº¡y bash script/cronjob) Ä‘á»ƒ quáº£n lÃ½ luá»“ng cháº¡y tá»± Ä‘á»™ng theo ngÃ y/tuáº§n, tá»± Ä‘á»™ng retry khi lá»—i pipeline.
5. **Há»‡ thá»‘ng Cáº£nh bÃ¡o (Alerting):** TÃ­ch há»£p webhook (Discord/Telegram) Ä‘á»ƒ tá»± Ä‘á»™ng gá»­i tin bÃ¡o cÃ¡o tÃ¬nh hÃ¬nh xá»­ lÃ½ lá»—i